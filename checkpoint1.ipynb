{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "807y-viHLvcX"
      },
      "source": [
        "# Checkpoint 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSWG3XrALvcY"
      },
      "source": [
        "Reminder:\n",
        "\n",
        "- You are being evaluated for completion and effort in this checkpoint.\n",
        "- Avoid manual labor / hard coding as much as possible, everything we've taught you so far are meant to simplify and automate your process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIrzZQV1LvcY"
      },
      "source": [
        "We will be working with the same `states_edu.csv` that you should already be familiar with from the tutorial.\n",
        "\n",
        "We investigated Grade 8 reading score in the tutorial. For this checkpoint, you are asked to investigate another test. Here's an overview:\n",
        "\n",
        "* Choose a specific response variable to focus on\n",
        ">Grade 4 Math, Grade 4 Reading, Grade 8 Math\n",
        "* Pick or create features to use\n",
        ">Will all the features be useful in predicting test score? Are some more important than others? Should you standardize, bin, or scale the data?\n",
        "* Explore the data as it relates to that test\n",
        ">Create at least 2 visualizations (graphs), each with a caption describing the graph and what it tells us about the data\n",
        "* Create training and testing data\n",
        ">Do you want to train on all the data? Only data from the last 10 years? Only Michigan data?\n",
        "* Train a ML model to predict outcome\n",
        ">Define what you want to predict, and pick a model in sklearn to use (see sklearn <a href=\"https://scikit-learn.org/stable/modules/linear_model.html\">regressors</a>).\n",
        "\n",
        "\n",
        "Include comments throughout your code! Every cleanup and preprocessing task should be documented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8igM3n4LvcY"
      },
      "source": [
        "<h2> Data Cleanup </h2>\n",
        "\n",
        "Import `numpy`, `pandas`, and `matplotlib`.\n",
        "\n",
        "(Feel free to import other libraries!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7kbKOkXLvcY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrwQg8FALvcY"
      },
      "source": [
        "Load in the \"states_edu.csv\" dataset and take a look at the head of the data\n",
        "\n",
        "---\n",
        "\n",
        ":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EasiouKLvcY"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"starbucks.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOoT7EDFLvcY"
      },
      "source": [
        "You should always familiarize yourself with what each column in the dataframe represents. Read about the states_edu dataset here: https://www.kaggle.com/noriuk/us-education-datasets-unification-project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMla6OtoLvcY"
      },
      "source": [
        "Use this space to rename columns, deal with missing data, etc. _(optional)_\n",
        "\n",
        "1.   remaning columns for consistency\n",
        "2.   handling missing data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbvodEpjLvcY"
      },
      "outputs": [],
      "source": [
        "# Renaming columns to lowercase and replacing spaces with underscores\n",
        "df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "# Filling missing values in important columns with the median\n",
        "df['avg_math_4_score'].fillna(df['avg_math_4_score'].median(), inplace=True)\n",
        "df['avg_math_8_score'].fillna(df['avg_math_8_score'].median(), inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAiG2RuFLvcZ"
      },
      "source": [
        "<h2>Exploratory Data Analysis (EDA) </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45YR07HJLvcZ"
      },
      "source": [
        "Chosen one of Grade 4 Reading, Grade 4 Math, or Grade 8 Math to focus on: Grade 4 math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvcH8kXZLvcZ"
      },
      "source": [
        "How many years of data are logged in our dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLgSpc2pLvcZ"
      },
      "outputs": [],
      "source": [
        "# Focus on Grade 4 Math and check how many unique years of data we have\n",
        "grade_4_math_data = df[~df['avg_math_4_score'].isnull()]\n",
        "\n",
        "# Get the number of unique years\n",
        "unique_years = grade_4_math_data['year'].nunique()\n",
        "\n",
        "# Display the result\n",
        "print(f\"There are {unique_years} unique years of data for Grade 4 Math.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LpZmAvXLvcZ"
      },
      "source": [
        "# Let's compare Michigan to Ohio. Which state has the higher average across all years in the test you chose?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fWZIxDbLvcZ"
      },
      "outputs": [],
      "source": [
        "# Focusing on Grade 4 Math and comparing Michigan to Ohio\n",
        "grade_4_math_data = df[~df['avg_math_4_score'].isnull()]\n",
        "\n",
        "# Filter for Michigan and Ohio\n",
        "michigan_data = grade_4_math_data[grade_4_math_data['state'] == 'MICHIGAN']\n",
        "ohio_data = grade_4_math_data[grade_4_math_data['state'] == 'OHIO']\n",
        "\n",
        "# Calculate the average for each state\n",
        "michigan_avg = michigan_data['avg_math_4_score'].mean()\n",
        "ohio_avg = ohio_data['avg_math_4_score'].mean()\n",
        "\n",
        "# Display the results\n",
        "michigan_avg, ohio_avg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hovWsQFjLvcZ"
      },
      "source": [
        "Find the average for your chosen test across all states in 2019"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8CBL-BsLvcZ"
      },
      "outputs": [],
      "source": [
        "# Focusing on Grade 4 Math and filtering for the year 2019\n",
        "grade_4_math_2019 = df[(df['year'] == 2019) & (~df['avg_math_4_score'].isnull())]\n",
        "\n",
        "# Calculate the average score for Grade 4 Math across all states in 2019\n",
        "average_2019_grade_4_math = grade_4_math_2019['avg_math_4_score'].mean()\n",
        "\n",
        "# Display the result\n",
        "print(f\"The average Grade 4 Math score across all states in 2019 is {average_2019_grade_4_math:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb3GZ6lvLvcZ"
      },
      "source": [
        "For each state, find a maximum value for your chosen test score\n",
        "\n",
        "*   Find the max value for Grade 4 math for each state\n",
        "*   Find the mac value for Grade 8 math for each state\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P89vTZ6rLvcZ"
      },
      "outputs": [],
      "source": [
        "# Step 1: Find the maximum Grade 4 Math score for each state\n",
        "max_grade_4_math_per_state = df.groupby('state')['avg_math_4_score'].max()\n",
        "\n",
        "# Step 2: Find the maximum Grade 8 Math score for each state\n",
        "max_grade_8_math_per_state = df.groupby('state')['avg_math_8_score'].max()\n",
        "\n",
        "# Display both results\n",
        "print(\"Maximum Grade 4 Math score per state:\")\n",
        "print(max_grade_4_math_per_state)\n",
        "\n",
        "print(\"\\nMaximum Grade 8 Math score per state:\")\n",
        "print(max_grade_8_math_per_state)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mXxYlqALvcZ"
      },
      "source": [
        "*Refer to the `Grouping and Aggregating` section in Tutorial 0 if you are stuck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t-7by5MLvcZ"
      },
      "source": [
        "<h2> Feature Engineering </h2>\n",
        "\n",
        "After exploring the data, you can choose to modify features that you would use to predict the performance of the students on your chosen response variable.\n",
        "\n",
        "You can also create your own features. For example, perhaps you figured that maybe a state's expenditure per student may affect their overall academic performance so you create a expenditure_per_student feature.\n",
        "\n",
        "Use this space to modify or create features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3PNq89MLvcZ"
      },
      "outputs": [],
      "source": [
        "# Ensure there are no NaN values in the relevant columns\n",
        "df['total_expenditure'].fillna(0, inplace=True)\n",
        "df['enroll'].fillna(1, inplace=True)  # Avoid division by zero\n",
        "\n",
        "# Step 1: Create expenditure_per_student feature\n",
        "df['expenditure_per_student'] = df['total_expenditure'] / df['enroll']\n",
        "\n",
        "# Step 2: Justify the feature creation\n",
        "# This feature is created to capture how much money is spent on each student, which could have an impact on student performance.\n",
        "\n",
        "# Display the new column in the dataframe\n",
        "df[['state', 'year', 'expenditure_per_student']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPht297FLvcZ"
      },
      "source": [
        "Feature engineering justification: **<One feature is expenditure per student, because we may want to see how investment in education affects overall performance\\>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbPqPfXzLvcZ"
      },
      "source": [
        "<h2>Visualization</h2>\n",
        "\n",
        "Investigate the relationship between your chosen response variable and at least two predictors using visualizations. Write down your observations.\n",
        "\n",
        "**Visualization 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfVovl7_LvcZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scatter plot of Grade 4 Math score vs expenditure_per_student\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df['expenditure_per_student'], df['avg_math_4_score'], color='blue', alpha=0.5)\n",
        "plt.title('Grade 4 Math Score vs Expenditure Per Student')\n",
        "plt.xlabel('Expenditure Per Student')\n",
        "plt.ylabel('Grade 4 Math Score')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9DYAT6xLvcZ"
      },
      "source": [
        "**<Grade 4 math score vs expenditure per student>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv7DYt22LvcZ"
      },
      "source": [
        "**Visualization 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqp_e1kvLvcZ"
      },
      "outputs": [],
      "source": [
        "# Scatter plot of Grade 4 Math score vs federal_revenue\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df['federal_revenue'], df['avg_math_4_score'], color='green', alpha=0.5)\n",
        "plt.title('Grade 4 Math Score vs Federal Revenue')\n",
        "plt.xlabel('Federal Revenue')\n",
        "plt.ylabel('Grade 4 Math Score')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgB9wr1ULvcZ"
      },
      "source": [
        "** *italicized text*<grade 4 math scores vs fed revenue>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6jjW2zELvcZ"
      },
      "source": [
        "<h2> Data Creation </h2>\n",
        "\n",
        "_Use this space to create train/test data_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-En9ikjLvcZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaqprlkhLvcZ"
      },
      "outputs": [],
      "source": [
        "X = df[['expenditure_per_student', 'federal_revenue']]\n",
        "y = df['avg_math_4_score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZvsQjheLvca"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1LyWQl6Lvca"
      },
      "source": [
        "<h2> Prediction </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfZNKL4gLvca"
      },
      "source": [
        "ML Models [Resource](https://medium.com/@vijaya.beeravalli/comparison-of-machine-learning-classification-models-for-credit-card-default-data-c3cf805c9a5a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPwAXdFcLvca"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lEw_5BSLvca"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhZbbYk7Lvca"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auOZOUhZLvcd"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOf8UsV3Lvcd"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDZOkwRYLvcd"
      },
      "source": [
        "Choose some metrics to evaluate the performance of your model, some of them are mentioned in the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piYkHEAtLvcd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "# Evaluate model performance using Mean Squared Error (MSE) and R-squared (R2 Score)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared (R2 Score): {r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54iMj9fRLvcd"
      },
      "source": [
        "We have copied over the graphs that visualize the model's performance on the training and testing set.\n",
        "\n",
        "Change `col_name` and modify the call to `plt.ylabel()` to isolate how a single predictor affects the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emY_pClfLvcd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "col_name = 'expenditure_per_student'\n",
        "\n",
        "f = plt.figure(figsize=(12,6))\n",
        "plt.scatter(X_train[col_name], y_train, color=\"red\")\n",
        "plt.scatter(X_train[col_name], model.predict(X_train), color=\"green\")\n",
        "plt.legend(['True Training', 'Predicted Training'])\n",
        "plt.xlabel(col_name)\n",
        "plt.ylabel('Grade 4 Math Score')\n",
        "plt.title(\"Model Behavior On Training Set\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WApUHIeILvcd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f = plt.figure(figsize=(12,6))\n",
        "plt.scatter(X_test[col_name], y_test, color=\"blue\")\n",
        "plt.scatter(X_test[col_name], model.predict(X_test), color=\"black\")\n",
        "plt.legend(['True Testing', 'Predicted Testing'])\n",
        "plt.xlabel(col_name)\n",
        "plt.ylabel('Grade 4 Math Score')\n",
        "plt.title(\"Model Behavior On Testing Set\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6cf8df3ff69f85f626faf55c10df6fe2cb9d1236b4dc73844ee4dc01369c2c99"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}